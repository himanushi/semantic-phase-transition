# Experiment 8: Trace of π in the Universal Permeation Function

## 背景と動機

exp3ef で発見した普遍浸透関数 g(l/L) の erf フィットにおいて σ ≈ 0.55。一方 1/√π ≈ 0.5642。この 2.5% の差は偶然か、超球面幾何の帰結か？

Transformer の埋め込み空間は高次元超球面とみなせる（nGPT, NVIDIA 2024）。球面上のトークン移動にはπが幾何学的に関与する。もし g(l/L) が球面拡散方程式の解であれば、erf の特性パラメータに π が自然に出現するはず。

## 実験設定

- データ: exp3ef の既存 JSON（Part A/B）
- モデル: GPT-2 small (12層), GPT-2 medium (24層)
- Part C のみモデルロード必要（WikiText-2, 500 samples）

### 成功基準（事前登録済み）

以下のいずれか1つが成立すれば「πの痕跡あり」と判定:

1. erf σ = 1/√π が p > 0.05 で棄却できない（8A）
2. π含有0パラメータモデルが既存モデルより BIC 良好（8B）
3. 累積回転角が π±0.1 以内に集中（8C, 語の90%以上）

---

## 8A: erf σ パラメータの π 検定

### 手法

exp3ef のデータから g_mean と l_norm を読み込み、erf(x / (σ√2)) を:

1. σ = free でフィット → RSS_free
2. σ = 1/√π に固定 → RSS_fixed
3. 尤度比検定: χ² = n·ln(RSS_fixed / RSS_free), df=1

### 結果

| Model        | n   | σ_free | σ_π = 1/√π | 差    | RSS_free | RSS_fixed | χ²    | **p値**   |
| ------------ | --- | ------ | ---------- | ----- | -------- | --------- | ----- | --------- |
| GPT-2 small  | 13  | 0.5455 | 0.5642     | 3.32% | 0.0664   | 0.0684    | 0.385 | **0.535** |
| GPT-2 medium | 25  | 0.5907 | 0.5642     | 4.71% | 0.1497   | 0.1580    | 1.349 | **0.245** |

| Model        | R²(free) | R²(fixed) |
| ------------ | -------- | --------- |
| GPT-2 small  | 0.9471   | 0.9455    |
| GPT-2 medium | 0.9443   | 0.9412    |

### 解釈

**両モデルとも H₀(σ = 1/√π) を棄却できない。**

- GPT-2 small: p = 0.535 — σ*free と σ*π の RSS 差はわずか 3%。統計的に有意な差ではない
- GPT-2 medium: p = 0.245 — σ_free はπ値より 4.7% 大きいが、n=25 でもまだ棄却に至らない

σ_free が small では 1/√π より小さく（0.545 < 0.564）、medium では大きい（0.591 > 0.564）ことは注目に値する。1/√π はちょうど両者の中間に位置する。

**判定: πと整合的** ✅

---

## 8B: π含有モデルの BIC 比較

### 手法

g_mean に以下のπ含有モデルをフィットし、exp3ef の既存モデル（power_law, erf, sigmoid 等）と BIC 比較:

| モデル    | 式                  | パラメータ数 |
| --------- | ------------------- | ------------ |
| cos_pi_0p | [1 - cos(πx)] / 2   | 0            |
| cos_pi_1p | [1 - cos(πx^α)] / 2 | 1            |
| sin_pi_0p | sin(πx / 2)         | 0            |
| sin_pi_1p | sin(πx^α / 2)       | 1            |

### 結果: GPT-2 small

| Rank | Model       | k   | R²     | BIC    | π?  |
| ---- | ----------- | --- | ------ | ------ | --- |
| 1    | erf         | 1   | 0.9471 | -66.03 |     |
| 2    | sin_pi_1p   | 1   | 0.9333 | -63.02 | ★   |
| 3    | log         | 1   | 0.9283 | -62.08 |     |
| 4    | sin_pi_0p   | 0   | 0.9121 | -61.98 | ★   |
| 5    | exponential | 1   | 0.9256 | -61.59 |     |
| 6    | cos_pi_1p   | 1   | 0.9250 | -61.48 | ★   |
| 7    | sigmoid     | 2   | 0.9366 | -61.10 |     |
| 8    | power_law   | 1   | 0.9199 | -60.63 |     |
| 9    | cos_pi_0p   | 0   | 0.8111 | -52.05 | ★   |

erf が BIC 最良。πモデルは2位以下だが、sin_pi_0p（0パラメータ）が R²=0.912 で4位に入り、パラメータなしとしては非常に優秀。

### 結果: GPT-2 medium

| Rank  | Model         | k     | R²         | BIC         | π?    |
| ----- | ------------- | ----- | ---------- | ----------- | ----- |
| **1** | **sin_pi_1p** | **1** | **0.9793** | **-149.44** | **★** |
| 2     | sigmoid       | 2     | 0.9814     | -148.90     |       |
| 3     | cos_pi_1p     | 1     | 0.9746     | -144.37     | ★     |
| 4     | cos_pi_0p     | 0     | 0.9498     | -130.59     | ★     |
| 5     | log           | 1     | 0.9561     | -130.70     |       |
| 6     | power_law     | 1     | 0.9501     | -127.48     |       |
| 7     | erf           | 1     | 0.9443     | -124.74     |       |
| 8     | sin_pi_0p     | 0     | 0.8832     | -109.46     | ★     |
| 9     | exponential   | 1     | 0.8896     | -107.64     |       |

**sin(πx^α / 2) が BIC 最良** (α=1.370)。sigmoid (2パラメータ) と僅差だが、パラメータ数が少ない分 BIC で勝利。cos_pi_0p（0パラメータ）も R²=0.950 で、パラメータなしモデルとしては erf (1パラメータ, R²=0.944) と同等。

### 解釈

- **GPT-2 small**: erf が最良。πモデルは有力な対抗馬だが未勝利
- **GPT-2 medium**: sin(πx^α / 2) が BIC 最良。データ点が多い medium で、πの構造がより鮮明に浮かぶ
- **cos_pi_0p の健闘**: 0パラメータで R²>0.95（medium）は注目。[1 - cos(πx)]/2 は「半周期コサイン」であり、球面上の測地線拡散と幾何学的に対応する

**判定: GPT-2 medium で成功基準の境界上** — 0パラメータモデル単独ではBIC最良にならなかったが、1パラメータのsin_pi_1p が全モデル中1位 ⚠️

---

## 8C: レイヤー間回転角の測定

### 手法

残差ストリームの隣接レイヤー間の回転角を測定:

- θ(l) = arccos(cos_sim(resid_post(l), resid_post(l-1)))
- 累積回転角 Θ = Σ θ(l)

WikiText-2 から 500 トークン位置、および曖昧語9語のプロンプトで測定。

### WikiText-2 統計

| 指標                 | 値                |
| -------------------- | ----------------- |
| Θ 平均               | 4.967 ± 0.320 rad |
| Θ/π 平均             | 1.581 ± 0.102     |
| πの最近整数倍        | 2                 |
| 最近整数倍からの偏差 | 0.419             |
| π±0.1 以内の割合     | 0.0%              |

### レイヤーごとの回転角

| Layer | θ mean (rad) | θ std | 備考                        |
| ----- | ------------ | ----- | --------------------------- |
| 0     | **1.382**    | 0.041 | embedding → L0 で大きな回転 |
| 1     | 0.249        | 0.054 |                             |
| 2     | 0.251        | 0.057 |                             |
| 3     | 0.253        | 0.049 |                             |
| 4     | 0.243        | 0.040 |                             |
| 5     | 0.274        | 0.056 |                             |
| 6     | 0.278        | 0.045 |                             |
| 7     | 0.320        | 0.056 |                             |
| 8     | 0.296        | 0.046 |                             |
| 9     | 0.318        | 0.045 |                             |
| 10    | 0.392        | 0.054 |                             |
| 11    | **0.713**    | 0.099 | 最終層で大きな回転          |

Layer 0 (embedding→L0) の回転が支配的（θ≈1.38 rad ≈ 79°）。Layer 1-10 は θ≈0.25-0.39 rad (14-22°) で比較的均一。Layer 11 は θ≈0.71 rad (41°) で unembedding 再構成に対応。

### 曖昧語プロンプト Θ/π

| Word    | neutral | strong_A | strong_B |
| ------- | ------- | -------- | -------- |
| bank    | 1.414   | 1.455    | 1.556    |
| bass    | 1.307   | 1.406    | 1.389    |
| bat     | 1.379   | 1.375    | 1.439    |
| crane   | 1.257   | 1.356    | 1.370    |
| light   | 1.420   | 1.535    | 1.533    |
| match   | 1.471   | 1.427    | 1.499    |
| pitcher | 1.343   | 1.431    | 1.425    |
| rock    | 1.371   | 1.407    | 1.462    |
| spring  | 1.408   | 1.438    | 1.442    |

全プロンプトで Θ/π ≈ 1.26〜1.56。πの整数倍（1 or 2）には収束せず。

### 解釈

- Θ/π ≈ 1.58 (WikiText) / ≈ 1.40 (プロンプト) — πの整数倍ではない
- ただし Θ/π ≈ π/2 ≈ 1.571 に近い点は興味深い（WikiText: 1.581 vs π/2 = 1.571、差0.6%）
- 文脈が強いほど Θ/π がやや増加する傾向（neutral < strong）

**判定: 事前登録した成功基準は未達** ❌

---

## 総合判定

| 基準 | 条件                            | GPT-2 small   | GPT-2 medium           | 判定       |
| ---- | ------------------------------- | ------------- | ---------------------- | ---------- |
| 8A   | σ=1/√π が p>0.05 で棄却できない | p=0.535 ✅    | p=0.245 ✅             | **成立**   |
| 8B   | π含有0pモデルが BIC 最良        | erf が最良 ❌ | sin_pi_1p(1p)が最良 ⚠️ | **部分的** |
| 8C   | 累積回転角が π±0.1 に90%+       | 0% ❌         | —                      | **不成立** |

### 結論

**πの痕跡は「示唆的だが決定的ではない」。**

1. **8A が最も強い証拠**: 両モデルで σ=1/√π を棄却できない。erf の σ パラメータが 1/√π と整合的であることは、g(l/L) の背後に正規分布的（=球面拡散的）なメカニズムが存在する可能性を示唆
2. **8B は medium で興味深い結果**: sin(πx^α / 2) が BIC 1位。ただし事前登録した基準は「0パラメータモデルが最良」であり、厳密には不成立。cos_pi_0p (0パラメータ) が R²=0.950 で erf (R²=0.944) を上回った点は注目に値する
3. **8C は否定的**: 累積回転角はπの整数倍に収束しない。ただし Θ/π ≈ π/2 という関係は偶然とするには近すぎる可能性がある（要追加検証）

### 今後の可能性

- **Θ/π ≈ π/2 の検証**: WikiText で Θ ≈ π²/2 ≈ 4.935 (実測 4.967) の一致を、より大きなモデル（GPT-2 medium, Pythia 等）で確認
- **Layer 0 を除外した累積角**: L0 の θ≈1.38 は embedding 空間の特殊性。L1-L11 の累積 Θ' ≈ 3.59 ≈ 1.14π — これはπに近い
- **erf σ のモデルサイズ依存性**: small (0.545) → medium (0.591) と σ が増加。1/√π (0.564) へ収束するか発散するかを、より多くのモデルサイズで検証
